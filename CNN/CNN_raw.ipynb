{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Model being implemented: CNN (on the raw extracted dataset)"
      ],
      "metadata": {
        "id": "RnZYZiLaco92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.signal import correlate2d"
      ],
      "metadata": {
        "id": "-1J2sJt-fTXc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Implementing CNN from scratch using NumPy (CPU-only)\")\n",
        "\n",
        "# Load dataset\n",
        "X_features = np.load(\"X_features.npy\")\n",
        "y_labels = np.load(\"y_labels.npy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c9bL8eljVu5",
        "outputId": "925ae122-5fc9-4e38-a5ed-ea54ab3027e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implementing CNN from scratch using NumPy (CPU-only)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "T81mIJYhdC6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_features)\n",
        "\n",
        "# Reshape to 2D \"images\"\n",
        "height = int(np.sqrt(X_scaled.shape[1]))\n",
        "width = int(np.ceil(X_scaled.shape[1] / height))\n",
        "padding = height * width - X_scaled.shape[1]\n",
        "X_padded = np.pad(X_scaled, ((0, 0), (0, padding)), mode='constant')\n",
        "X_reshaped = X_padded.reshape(-1, 1, height, width)  # (N, C, H, W)\n",
        "\n",
        "# Split into train (60%), validation (20%), and test (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_reshaped, y_labels, test_size=0.4, random_state=42, stratify=y_labels)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
      ],
      "metadata": {
        "id": "wYuWLYoVjaWq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchCNN:\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        self.params = {}\n",
        "        # Conv Layer 1: 3x3 kernel, 8 filters\n",
        "        self.params['W1'] = np.random.randn(8, 1, 3, 3) * 0.1\n",
        "        self.params['b1'] = np.zeros(8)\n",
        "        # Conv Layer 2: 3x3 kernel, 16 filters\n",
        "        self.params['W2'] = np.random.randn(16, 8, 3, 3) * 0.1\n",
        "        self.params['b2'] = np.zeros(16)\n",
        "        # FC Layer\n",
        "        flattened_size = 16 * (height//4) * (width//4)\n",
        "        self.params['W3'] = np.random.randn(flattened_size, num_classes) * 0.1\n",
        "        self.params['b3'] = np.zeros(num_classes)\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "    def _conv2d(self, x, W, b, stride=1, pad=1):\n",
        "        N, C, H, W_in = x.shape\n",
        "        F, _, HH, WW = W.shape\n",
        "\n",
        "        x_pad = np.pad(x, ((0,0), (0,0), (pad,pad), (pad,pad)), mode='constant')\n",
        "        H_out = (H + 2*pad - HH) // stride + 1\n",
        "        W_out = (W_in + 2*pad - WW) // stride + 1\n",
        "\n",
        "        out = np.zeros((N, F, H_out, W_out))\n",
        "\n",
        "        for f in range(F):\n",
        "            for i in range(H_out):\n",
        "                for j in range(W_out):\n",
        "                    ii, jj = i*stride, j*stride\n",
        "                    out[:, f, i, j] = np.sum(\n",
        "                        x_pad[:, :, ii:ii+HH, jj:jj+WW] * W[f],\n",
        "                        axis=(1, 2, 3))\n",
        "            out[:, f] += b[f]\n",
        "        return out\n",
        "\n",
        "    def _maxpool2d(self, x, pool_size=2, stride=2):\n",
        "        N, C, H, W = x.shape\n",
        "        H_out = (H - pool_size) // stride + 1\n",
        "        W_out = (W - pool_size) // stride + 1\n",
        "\n",
        "        out = np.zeros((N, C, H_out, W_out))\n",
        "\n",
        "        for i in range(H_out):\n",
        "            for j in range(W_out):\n",
        "                ii, jj = i*stride, j*stride\n",
        "                out[:, :, i, j] = np.max(\n",
        "                    x[:, :, ii:ii+pool_size, jj:jj+pool_size],\n",
        "                    axis=(2, 3))\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.cache = {}\n",
        "        self.cache['Z1'] = self._conv2d(x, self.params['W1'], self.params['b1'])\n",
        "        self.cache['A1'] = self.relu(self.cache['Z1'])\n",
        "        self.cache['P1'] = self._maxpool2d(self.cache['A1'])\n",
        "\n",
        "        self.cache['Z2'] = self._conv2d(self.cache['P1'], self.params['W2'], self.params['b2'])\n",
        "        self.cache['A2'] = self.relu(self.cache['Z2'])\n",
        "        self.cache['P2'] = self._maxpool2d(self.cache['A2'])\n",
        "\n",
        "        self.cache['F'] = self.cache['P2'].reshape(self.cache['P2'].shape[0], -1)\n",
        "        self.cache['Z3'] = np.dot(self.cache['F'], self.params['W3']) + self.params['b3']\n",
        "        self.cache['A3'] = self.softmax(self.cache['Z3'])\n",
        "        return self.cache['A3']\n",
        "\n",
        "    def compute_loss(self, outputs, y_true):\n",
        "        correct_probs = outputs[np.arange(len(y_true)), y_true]\n",
        "        return -np.mean(np.log(correct_probs + 1e-10))\n",
        "\n",
        "    def backward(self, x, y_true, lr=0.001):\n",
        "        m = len(y_true)\n",
        "        grads = {key: np.zeros_like(val) for key, val in self.params.items()}\n",
        "\n",
        "        # Output layer gradient\n",
        "        dZ3 = self.cache['A3'].copy()\n",
        "        dZ3[np.arange(m), y_true] -= 1\n",
        "        dZ3 /= m\n",
        "\n",
        "        # FC layer gradients\n",
        "        grads['W3'] = np.dot(self.cache['F'].T, dZ3)\n",
        "        grads['b3'] = np.sum(dZ3, axis=0)\n",
        "\n",
        "        dF = np.dot(dZ3, self.params['W3'].T)\n",
        "        dP2 = dF.reshape(self.cache['P2'].shape)\n",
        "\n",
        "        # MaxPool2 backward\n",
        "        dA2 = np.zeros_like(self.cache['A2'])\n",
        "        for n in range(dP2.shape[0]):\n",
        "            for c in range(dP2.shape[1]):\n",
        "                for i in range(dP2.shape[2]):\n",
        "                    for j in range(dP2.shape[3]):\n",
        "                        ii, jj = i * 2, j * 2\n",
        "                        window = self.cache['A2'][n, c, ii:ii+2, jj:jj+2]\n",
        "                        mask = (window == np.max(window))\n",
        "                        dA2[n, c, ii:ii+2, jj:jj+2] += mask * dP2[n, c, i, j]\n",
        "\n",
        "        # Conv2 backward\n",
        "        dZ2 = dA2 * (self.cache['Z2'] > 0)\n",
        "        P1_padded = np.pad(self.cache['P1'], ((0,0),(0,0),(1,1),(1,1)), mode='constant')\n",
        "\n",
        "        for f in range(self.params['W2'].shape[0]):\n",
        "            for c in range(self.params['W2'].shape[1]):\n",
        "                grad = np.zeros_like(self.params['W2'][f,c])\n",
        "                for i in range(dZ2.shape[2]):\n",
        "                    for j in range(dZ2.shape[3]):\n",
        "                        input_patch = P1_padded[:, c, i:i+3, j:j+3]\n",
        "                        grad_contrib = dZ2[:, f, i, j][:, np.newaxis, np.newaxis]\n",
        "                        grad += np.sum(input_patch * grad_contrib, axis=0)\n",
        "                grads['W2'][f,c] = grad / m\n",
        "            grads['b2'][f] = np.sum(dZ2[:, f]) / m\n",
        "\n",
        "        # dP1 calculation (Conv2 backward to Conv1 input)\n",
        "        dP1 = np.zeros_like(self.cache['P1'])\n",
        "        dZ2_padded = np.pad(dZ2, ((0,0), (0,0), (1,1), (1,1)), mode='constant')\n",
        "        for n in range(x.shape[0]):\n",
        "            for f in range(self.params['W2'].shape[0]):\n",
        "                for c in range(self.params['W2'].shape[1]):\n",
        "                    flipped_kernel = np.rot90(self.params['W2'][f, c], 2)\n",
        "                    for i in range(dZ2.shape[2]):\n",
        "                        for j in range(dZ2.shape[3]):\n",
        "                            ii, jj = i, j\n",
        "                            if ii + 3 <= dP1.shape[2] and jj + 3 <= dP1.shape[3]:\n",
        "                                dP1[n, c, ii:ii+3, jj:jj+3] += dZ2[n, f, i, j] * flipped_kernel\n",
        "\n",
        "\n",
        "        # MaxPool1 backward\n",
        "        dA1 = np.zeros_like(self.cache['A1'])\n",
        "        for n in range(dP1.shape[0]):\n",
        "            for c in range(dP1.shape[1]):\n",
        "                for i in range(dP1.shape[2]):\n",
        "                    for j in range(dP1.shape[3]):\n",
        "                        ii, jj = i * 2, j * 2\n",
        "                        window = self.cache['A1'][n, c, ii:ii+2, jj:jj+2]\n",
        "                        mask = (window == np.max(window))\n",
        "                        dA1[n, c, ii:ii+2, jj:jj+2] += mask * dP1[n, c, i, j]\n",
        "\n",
        "        # Conv1 backward\n",
        "        dZ1 = dA1 * (self.cache['Z1'] > 0)\n",
        "        x_pad = np.pad(x, ((0,0), (0,0), (1,1), (1,1)), mode='constant')\n",
        "\n",
        "        for f in range(self.params['W1'].shape[0]):\n",
        "            for c in range(self.params['W1'].shape[1]):\n",
        "                grad = np.zeros_like(self.params['W1'][f,c])\n",
        "                for i in range(dZ1.shape[2]):\n",
        "                    for j in range(dZ1.shape[3]):\n",
        "                        input_patch = x_pad[:, c, i:i+3, j:j+3]\n",
        "                        grad_contrib = dZ1[:, f, i, j][:, np.newaxis, np.newaxis]\n",
        "                        grad += np.sum(input_patch * grad_contrib, axis=0)\n",
        "                grads['W1'][f,c] = grad / m\n",
        "            grads['b1'][f] = np.sum(dZ1[:, f]) / m\n",
        "\n",
        "        # Gradient Clipping (to avoid explosion)\n",
        "        for param in self.params:\n",
        "            grads[param] = np.clip(grads[param], -1, 1)\n",
        "            self.params[param] -= lr * grads[param]\n"
      ],
      "metadata": {
        "id": "NT_mnAz7eGPh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train\n",
        "num_classes = len(np.unique(y_labels))\n",
        "cnn = ScratchCNN(input_shape=(1, height, width), num_classes=num_classes)\n",
        "\n",
        "# Training loop with accuracy tracking\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "train_losses = []\n",
        "val_accuracies = []\n",
        "train_accuracies = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    epoch_loss = 0\n",
        "    train_preds = []\n",
        "\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_X = X_train[i:i+batch_size]\n",
        "        batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = cnn.forward(batch_X)\n",
        "        loss = cnn.compute_loss(outputs, batch_y)\n",
        "        epoch_loss += loss\n",
        "\n",
        "        # Backward pass\n",
        "        cnn.backward(batch_X, batch_y, lr=0.001)\n",
        "\n",
        "        # Collect training predictions\n",
        "        train_preds.extend(np.argmax(outputs, axis=1))\n",
        "\n",
        "    # Calculate metrics\n",
        "    avg_loss = epoch_loss / (len(X_train) // batch_size)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, train_preds)\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    # Validation evaluation\n",
        "    val_outputs = cnn.forward(X_val)\n",
        "    val_preds = np.argmax(val_outputs, axis=1)\n",
        "    val_acc = accuracy_score(y_val, val_preds)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "38OuxZozlNkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation on all datasets\n",
        "def evaluate_model(X, y, name):\n",
        "    outputs = cnn.forward(X)\n",
        "    preds = np.argmax(outputs, axis=1)\n",
        "    acc = accuracy_score(y, preds)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
        "    return preds, acc"
      ],
      "metadata": {
        "id": "e8G_kMtpVKsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on all sets\n",
        "print(\"\\nFinal Evaluation Results:\")\n",
        "val_preds, val_acc = evaluate_model(X_val, y_val, \"Validation\")\n",
        "test_preds, test_acc = evaluate_model(X_test, y_test, \"Test\")\n",
        "train_preds, train_acc = evaluate_model(X_train[:2000], y_train[:2000], \"Train (subset)\")  # Smaller subset for faster evaluation\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(\"\\nValidation Set Classification Report:\")\n",
        "print(classification_report(y_val, val_preds))"
      ],
      "metadata": {
        "id": "3B8lIX3wVMQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.axhline(y=test_acc, color='r', linestyle='--', label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bUCJUkfTVadW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance comparison plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(['Train', 'Validation', 'Test'], [train_acc, val_acc, test_acc])\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Performance Comparison')\n",
        "for i, v in enumerate([train_acc, val_acc, test_acc]):\n",
        "    plt.text(i, v + 0.02, f\"{v:.4f}\", ha='center')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ekhc97USVSLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TEALnqGfdwR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}